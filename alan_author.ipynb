{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alan Author Strikes Again: More on Confirming Conjunctions of Disconfirmed Hypotheses\n",
    "\n",
    "This notebook corresponds to the following paper:\n",
    "\n",
    "- https://academic.oup.com/analysis/advance-article-abstract/doi/10.1093/analys/anad103/7731114\n",
    "\n",
    "## Importing Packages and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from scipy import stats\n",
    "from itertools import chain, combinations\n",
    "from IPython.display import Math, display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions for Powerset and Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Powerset function (without the empty set)\n",
    "def powerset(s):\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1,len(s)+1))\n",
    "\n",
    "# Function that calculates all marginal and joint probabilities for a set of probability distributions, given as matrix\n",
    "def probabilities(matrix):\n",
    "\n",
    "    # Size of matrix, number of random variables\n",
    "    length, width = matrix.shape\n",
    "    num_variables = np.log2(width).astype(int)\n",
    "    \n",
    "    # Create matrix with all Boolean combinations\n",
    "    binmat = np.array([np.fromstring(np.binary_repr(i,num_variables), dtype=np.uint8)==49 for i in range(0,width)])\n",
    "\n",
    "    # Pick all probabilities from matrix\n",
    "    result = [pd.Series(np.sum(np.all(binmat[:,i],axis=1)*matrix,axis = 1), name = f\"P{i}\") for i in powerset(range(num_variables))]\n",
    "\n",
    "    return pl.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating probability functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of variables and distributions\n",
    "number_variables = 3\n",
    "number_distributions = 1000000\n",
    "\n",
    "# Sampling from Dirichlet distribution, calculating relevant probabilities\n",
    "matrix = pl.DataFrame(np.random.dirichlet(np.ones(2**number_variables), number_distributions))\n",
    "df = probabilities(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_386cd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_386cd_level0_col0\" class=\"col_heading level0 col0\" >Effect</th>\n",
       "      <th id=\"T_386cd_level0_col1\" class=\"col_heading level0 col1\" >Conjunctive Prevalence</th>\n",
       "      <th id=\"T_386cd_level0_col2\" class=\"col_heading level0 col2\" >Conditional Prevalence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_386cd_row0_col0\" class=\"data row0 col0\" >Alan Author Effect</td>\n",
       "      <td id=\"T_386cd_row0_col1\" class=\"data row0 col1\" >0.025006</td>\n",
       "      <td id=\"T_386cd_row0_col2\" class=\"data row0 col2\" >0.100333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_386cd_row1_col0\" class=\"data row1 col0\" >Strong Alan Author Effect</td>\n",
       "      <td id=\"T_386cd_row1_col1\" class=\"data row1 col1\" >0.025006</td>\n",
       "      <td id=\"T_386cd_row1_col2\" class=\"data row1 col2\" >0.111471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbaa9e61710>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conjunction is confirmed (condition 1)\n",
    "conjunction_confirmation = (df[\"P(0, 1, 2)\"] > df[\"P(0,)\"]*df[\"P(1, 2)\"])\n",
    "conjunction_confirmation_mean = conjunction_confirmation.mean()\n",
    "\n",
    "# Conjuncts are disconfirmed (condition 2)\n",
    "conjuncts_disconfirmation = (df[\"P(0, 1)\"] < df[\"P(0,)\"]*df[\"P(1,)\"]) & (df[\"P(0, 2)\"] < df[\"P(0,)\"]*df[\"P(2,)\"])\n",
    "conjuncts_disconfirmation_mean = conjuncts_disconfirmation.mean()\n",
    "\n",
    "# Conjunction of negated conjuncts is confirmed (condition 3)\n",
    "negated_conjunction_confirmation = df[\"P(0, 1)\"] + df[\"P(0, 2)\"] - df[\"P(0, 1, 2)\"] < df[\"P(0,)\"] * (df[\"P(1,)\"] + df[\"P(2,)\"] - df[\"P(1, 2)\"] )\n",
    "negated_conjunction_confirmation_mean = negated_conjunction_confirmation.mean()\n",
    "\n",
    "# Alan Author Effect\n",
    "alan_author_effect = (conjunction_confirmation & conjuncts_disconfirmation)\n",
    "alan_author_effect_conjunctive_prevalence = alan_author_effect.mean()\n",
    "alan_author_effect_conditional_prevalence = alan_author_effect_conjunctive_prevalence/conjuncts_disconfirmation_mean\n",
    "\n",
    "# Strong Alan Author Effect (conjunctive)\n",
    "strong_alan_author_effect = (conjunction_confirmation & conjuncts_disconfirmation & negated_conjunction_confirmation)\n",
    "strong_alan_author_effect_conjunctive_prevalence = strong_alan_author_effect.mean()\n",
    "\n",
    "# Strong Alan Author Effect (conditional)\n",
    "antecedent_strong_alan_author_effect =  (conjuncts_disconfirmation & negated_conjunction_confirmation)\n",
    "antecedent_strong_alan_author_effect_mean = antecedent_strong_alan_author_effect.mean()\n",
    "strong_alan_author_effect_conditional_prevalence = strong_alan_author_effect_conjunctive_prevalence/antecedent_strong_alan_author_effect_mean\n",
    "\n",
    "# Prevalence of the effects\n",
    "alan_author_effect_conjunctive_prevalence\n",
    "alan_author_effect_conditional_prevalence\n",
    "strong_alan_author_effect_conjunctive_prevalence\n",
    "strong_alan_author_effect_conditional_prevalence\n",
    "\n",
    "# Collecting results\n",
    "\n",
    "results = pd.DataFrame([\n",
    "    [alan_author_effect_conjunctive_prevalence, alan_author_effect_conditional_prevalence],\n",
    "    [strong_alan_author_effect_conjunctive_prevalence, strong_alan_author_effect_conditional_prevalence],\n",
    "]).rename(columns={0: \"Conjunctive Prevalence\", 1: \"Conditional Prevalence\"})\n",
    "\n",
    "effects = pd.DataFrame([\n",
    "['Alan Author Effect'],\n",
    "['Strong Alan Author Effect'],\n",
    "]).rename(columns={0: \"Effect\"})\n",
    "\n",
    "pd.concat([effects,results],axis=1).style.hide()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
